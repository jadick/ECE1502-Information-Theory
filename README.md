## University of Toronto - ECE1502 - Information Theory - Fall 2023

### Lectures
| Lecture | Topic | Reference | Video|
| --- | --- | --- | --- |
| 1 | Introduction, source and channel coding, an axiomatic approach to defining a measure of "uncertainty" or entropy. | [Axiomatic Definition of Entropy](Reviews/axiomatic.pdf)  | [rec](https://vimeo.com/602154539/98a5f7124c) |
| 2 | Review of discrete probability, the weak law of large numbers. | [Discrete Probability Refresher](Reviews/Probability%20Review.pdf) | [rec](https://vimeo.com/605130763/91fc300adf) |
| 3 | Entropy, joint entropy, conditional entropy, the asymptotic equipartition property (AEP)	 | C&T Sections 2.1, 2.2, 3.1	 | [rec](https://vimeo.com/609804817/8a21c0cb28) |
| 4 | The AEP, typical sequences and properties of the typical set.	 | C&T Section 3.1	 | [rec](https://vimeo.com/611022935/e1a28e1443) |
| 5 | Source coding (variable-length and fixed-length codes) as an application of typicality.	 | C&T Section 3.2, Gallager Section 3.1	 | [rec](https://vimeo.com/613943749/438eec7be5) |
| 6 | High probability sets, mutual information, relative entropy.	 | C&T Sections 3.3, 2.3	 | [rec](https://vimeo.com/617292609/a759b7633f) |
| 7 | Information inequalities, Markov chains, the data-processing inequality.	 | C&T Sections 2.4, 2.5, 2.8	 | [rec](https://vimeo.com/620372953/fa68ef9543) |
| 8 | Data compression codes, prefix codes, Kraft's inequality.	 | C&T Sections 5.1, 5.2	 | [rec](https://vimeo.com/625946555/d9a1d9f963) |
| 9 | McMillan's theorem, entropy as a lower bound on expected codeword length, Shannon codes.	 | C&T Sections 5.3, 5.4, 5.5, [generatingfunctionology](https://www2.math.upenn.edu/~wilf/DownldGF.html) | [rec](https://vimeo.com/626843606/f11f628f24) |
| 10 | Approaching entropy by source extension, penalty for incorrect length assignment, Huffman codes.	 | C&T Sections 5.4, 5.6	 | [rec](https://vimeo.com/631889281/8c5ccb5d35) |
| 11 | Optimality of Huffman codes, dual tree codes, Tunstall codes.	 | C&T Section 5.8, Moser Sections 5.6, 5.7 (optional: [recent paper](https://dl.acm.org/doi/pdf/10.1145/3230653)) | [rec](https://vimeo.com/634908571/4fdd687bcb) |
| 12 | Arithmetic coding, Jensen's inequality, the log sum inequality.	 | C&T Section 5.9, Moser Section 5.3, C&T Sections 2.6, 2.7 | [rec](https://vimeo.com/636643390/681e921d0e) |
| 13 | Universal source coding:  Fitingof's scheme, Lempel-Ziv coding.	 | C&T Section 13.2, 13.4, 13.5 | [rec](https://vimeo.com/638025116/1d7f9e33f1) |
| 14 | Stochastic processes, stationarity, Markov chains, entropy rate, conditional entropy rate.	 | C&T Section 4.1, 4.2; also mentioned in the context of midterm question 5: [Fortune's Formula](http://www.fortunesformula.com/). by William Poundstone and  A Man for [All Markets](https://www.edwardothorp.com/books/a-man-for-all-markets/) by Edward O. Thorp. | [rec](https://vimeo.com/641229895/14494f6220) |
| 15 | Entropy rates for Markov chains in steady state, random walks on weighted graphs.	 | C&T Section 4.3	| [rec](https://vimeo.com/643028014/a8be70a4e3) |
| 16 | Discrete memoryless channels, information theoretic capacity.	 | C&T Section 7.1	| [rec](https://vimeo.com/643028019/20860bd591) |
| 17 | Comments on midterm; detour on rates in source and channel coding; back to the course: weakly symmetric channels.	 | C&T Section 7.2	| [rec(a)](https://vimeo.com/646624337/ed7cff3722), [rec(b)](https://vimeo.com/646624346/b1f620c2ca) |
| 18 | Computing channel capacity via the Blahut-Arimoto algorithm.	 | C&T Section 10.8	 | [rec](https://vimeo.com/647924330/911eb0700a) |
| 19 | Channel Coding Theorem (Part 1)	 | C&T Sections 7.4, 7.5, 7.6	| [rec](https://vimeo.com/649256262/e53c080747) |
| 20 | Channel Coding Theorem (Part 2)	 | C&T Sections 7.6, 7.7	| [rec](https://vimeo.com/652144767/5002802069) |
| 21 | Channel Coding Theorem (Part 3)	 | C&T Sections 7.7, 7.9	| [rec](https://vimeo.com/652144783/e0635edc4b) |
| 22 | Linear block codes; polar codes.	 | C&T Section 7.11, Moser Chapter 14.	| [rec](https://vimeo.com/654214162/b94cfc1775) |
| 23 | Differential entropy	 | C&T Sections 8.1, 8.2 8.3 8.4, 8.5, 8.6	| [rec](https://vimeo.com/655374738/fb49249738) |
| 24 | Capacity of the additive white Gaussian noise channel.	 | C&T Sections 9.1, 9.4	| [rec](https://vimeo.com/655661023/cb14b91975) |
